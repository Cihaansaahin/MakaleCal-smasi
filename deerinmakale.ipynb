{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e0f2d-f612-4c72-bf9f-28dde4110191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri yükleyelim\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential  # Model için Sequential sınıfı\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  # CNN için gerekli katmanlar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image  # Görüntü işlemleri için PIL kütüphanesi\n",
    "\n",
    "# 1. Veri setini yükleme ve eğitim/test setlerini ayırma\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# MNIST veri seti, 60,000 eğitim örneği ve 10,000 test örneği içerir.\n",
    "# X_train, 28x28 boyutunda el yazısı rakamları içeren görüntülerdir.\n",
    "# y_train, bu görüntülere karşılık gelen etiketlerdir (0-9 arası rakamlar).\n",
    "# X_test ve y_test ise test verilerini içerir.\n",
    "\n",
    "# 2. Veri ön işleme (normalizasyon ve yeniden şekillendirme)\n",
    "X_train = X_train / 255.0  # Görüntülerin piksel değerlerini 0-255 aralığından 0-1 aralığına dönüştürür.\n",
    "X_test = X_test / 255.0    # Aynı işlemi test verisi için yapıyoruz.\n",
    "\n",
    "# Görüntüleri modelin kabul edeceği şekle getirmek: (num_samples, height, width, channels)\n",
    "# Burada her görüntü 28x28 boyutunda olduğu için, her birini tek kanal (siyah-beyaz) olarak şekillendiriyoruz.\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# 3. Modeli tanımlama\n",
    "model = Sequential([\n",
    "    # İlk konvolüsyonel katman: 32 adet 3x3 filtre kullanarak, aktivasyon fonksiyonu olarak ReLU kullanıyoruz.\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),  # Maksimum havuzlama: 2x2 havuzlama alanı\n",
    "    Dropout(0.25),  # Dropout katmanı: Aşırı öğrenmeyi engellemek için rastgele bağlantıları devre dışı bırakır\n",
    "\n",
    "    # İkinci konvolüsyonel katman: 64 adet 3x3 filtre\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),  # Maksimum havuzlama: 2x2 havuzlama alanı\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),  # Konvolüsyonel katmanlardan çıkan özellik haritalarını düzleştirir (1D vektör haline getirir)\n",
    "    Dense(128, activation='relu'),  # Tam bağlantılı katman: 128 nöron, ReLU aktivasyon fonksiyonu\n",
    "    Dropout(0.5),  # Dropout: Bu katmanda da aşırı öğrenmeyi engellemeye çalışıyoruz\n",
    "    Dense(10, activation='softmax')  # Son katman: 10 sınıf için softmax aktivasyonu (sınıflandırma için)\n",
    "])\n",
    "\n",
    "# 4. Modeli derleme\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Derleme işleminde:\n",
    "# - Optimizer: Adam (öğrenme oranını uyarlayan bir optimizasyon algoritması)\n",
    "# - Loss: Sparse Categorical Crossentropy (çok sınıflı sınıflandırma problemi için uygun kayıp fonksiyonu)\n",
    "# - Metrics: Doğruluk (accuracy), modelin doğruluğunu değerlendireceğiz\n",
    "\n",
    "# 5. Modeli eğitme\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=64)\n",
    "\n",
    "# model.fit:\n",
    "# - X_train, y_train: Eğitim verisi ve etiketleri\n",
    "# - epochs: Modelin eğitim verisi üzerinde kaç kez geçeceğini belirtir (10 epok)\n",
    "# - validation_data: Modelin her epoch sonunda doğrulama (test) verisi üzerinde nasıl performans gösterdiğini görmemizi sağlar.\n",
    "# - batch_size: Eğitim sırasında her seferinde kaç örneğin işleneceğini belirler (64)\n",
    "\n",
    "# 6. Model performansını değerlendirme\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Modeli test verisiyle değerlendiririz.\n",
    "# test_loss: Test setindeki kayıp değeri\n",
    "# test_accuracy: Test setindeki doğruluk oranı\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# 7. Yeni bir görüntüyü yükleyip sınıflandırma\n",
    "\n",
    "# Yeni bir görüntü yükleyelim\n",
    "img = Image.open('yüklenecek görüntü.jpg').convert('L')  # Siyah-beyaz bir resim açıyoruz\n",
    "img = img.resize((28, 28))  # Görüntüyü 28x28 boyutlarına getiriyoruz\n",
    "img_array = np.array(img) / 255.0  # Görüntüyü normalize ediyoruz\n",
    "img_array = img_array.reshape(1, 28, 28, 1)  # Modelin beklediği şekilde şekillendiriyoruz\n",
    "\n",
    "# 8. Görüntü üzerinde tahmin yapma\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# model.predict: Yeni bir görüntü üzerinde tahmin yapar\n",
    "# prediction, 10 sınıf için modelin tahmin ettiği olasılıkları döndürür.\n",
    "\n",
    "# Tahmin edilen sınıf\n",
    "predicted_label = np.argmax(prediction)  # En yüksek olasılıkla tahmin edilen sınıf\n",
    "\n",
    "print(f\"Tahmin edilen sınıf: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad4489-45cc-4486-b4a4-cb6985b3555c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
